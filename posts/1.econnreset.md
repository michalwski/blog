# Parallel tests, Mac OS X misterious `econnreset` and backlog

## Background

Developing [MongooseIM](https://github.com/esl/MongooseIM) (XMPP server written in Erlang) we are adding more and more tests to cover new functionality
but also to improve existing code test coverage. Recently we got to the point
where single job on travis takes around 30-40 minutes, take a look at [this build](https://travis-ci.org/esl/MongooseIM/builds/117928318).
We decided to start reorganizing our tests to leverage `parallel` property
of common test's group. A single test case is usually a story in which 2 users connect
to the remote server and exchange some stanzas.

## The problem

Running these parallel tests on Linux was very smooth, we didn't see any unexpected errors.
Everything got more interesting when I started using this and writing my own parallel tests on my Mac OS X.
This is very powerful machine - Intel Core i7 2Ghz, 4 cores, 16GB of RAM
so I didn't expect any performance related issues. Everything was running just fine
until I added 7th test case in my group. Then I started observing strange
`econnreset` errors.

```erlang
{error,econnreset}
```

It seemed random because with every run, other test case was failing.
Also some times the error happened while opening the TCP connection to the server,
but sometimes it happened while reading data from the server. We (me and @pzel)
started investigating this issue. At the begging we thought that this is client
side problem, but no tracing confirmed this hypothesis, every error was
initiated by the server. Then we started to investigate the server side.
Guess what, again no tracing showed the error. Actually the server side looked clean.
Wanting to improve our tracing we read the `gen_tcp` documentation and we spotted the `backlog`
option which can be passed to `gen_tcp:listen/2` function.

## Explanation

The option sets the limit for the queue of incoming connections. The default value is 5, which indeed looks
quite small given I open over a dozen or several dozen sockets in my parallel group.
Now the question is, why the same value works fine on Linux but not on Mac OS X.
We found the explanation in [How TCP backlog works in Linux](http://veithen.github.io/2014/01/01/how-tcp-backlog-works-in-linux.html) blog post.
It turns out that MacOS X follows the single queue implementation and that's why our parallel tests
ran perfectly fine on Linux but had strange issue on Mac OS X.

## Solution

Fortunately the solution for the issue was very simple. It was enough to
increase the backlog value when starting the socket on server side
```erlang
gen_tcp:listen(5222, [{backlog, 100}])
```

If the solution is that simple then why it took us almost a day to figure it out? Good question, isn't it?
I don't have answer for that, but I decided to describe my problem and how we finally solved it
to hopefully safe someone else's time when (s)he observers similar strange issue.
